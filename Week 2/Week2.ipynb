{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "df = pd.read_json(r'C:\\Users\\Gabe\\PycharmProjects\\DataMining_2.2_BuildYourTextClassifiers\\controversial-comments.jsonl'\n",
    "                  , lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Convert all text to lowercase letters\n",
    "df['txt'] = df['txt'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Remove all punctuation from the text\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "\n",
    "def remove_punctuation(x):\n",
    "    x = ''.join(ch for ch in x if ch not in exclude)\n",
    "    return x\n",
    "\n",
    "\n",
    "df['txt'] = df['txt'].apply(remove_punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        con                                                txt  \\\n",
      "0         0  well  gre h he  ehng bu he belef whle he w n f...   \n",
      "1         0                                   u re rgh r preen   \n",
      "2         0  u hve gven n npu pr fr ng   wrng u hve n rguen...   \n",
      "3         0   ge he frurn bu he ren he wn he    h w  becue ...   \n",
      "4         0    fr fr n exper n pp n  wul en  gree h  h  l f...   \n",
      "...     ...                                                ...   \n",
      "949995    0   genunel cn unern hw nne cn uppr h  h pn  k u ...   \n",
      "949996    0    rener h ubre  fr cvl cunhpwwwrecrplcwkrulenr...   \n",
      "949997    0                                k n expln wh r nhng   \n",
      "949998    0                                               elee   \n",
      "949999    0   cph re knwn fr celebrng her pve feelng re u f...   \n",
      "\n",
      "                                                   tokens  \n",
      "0       [well, gre, h, he, ehng, bu, he, belef, whle, ...  \n",
      "1                                  [u, re, rgh, r, preen]  \n",
      "2       [u, hve, gven, n, npu, pr, fr, ng, wrng, u, hv...  \n",
      "3       [ge, he, frurn, bu, he, ren, he, wn, he, h, w,...  \n",
      "4       [fr, fr, n, exper, n, pp, n, wul, en, gree, h,...  \n",
      "...                                                   ...  \n",
      "949995  [genunel, cn, unern, hw, nne, cn, uppr, h, h, ...  \n",
      "949996  [rener, h, ubre, fr, cvl, cunhpwwwrecrplcwkrul...  \n",
      "949997                         [k, n, expln, wh, r, nhng]  \n",
      "949998                                             [elee]  \n",
      "949999  [cph, re, knwn, fr, celebrng, her, pve, feelng...  \n",
      "\n",
      "[950000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# C. Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    x = ''.join(ch for ch in x if ch not in stop_words)\n",
    "    return x\n",
    "\n",
    "\n",
    "df['txt'] = df['txt'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Apply NLTK's PoterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "df['tokens'] = df['txt'].apply(word_tokenize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        con                                                txt  \\\n",
      "0         0  well  gre h he  ehng bu he belef whle he w n f...   \n",
      "1         0                                   u re rgh r preen   \n",
      "2         0  u hve gven n npu pr fr ng   wrng u hve n rguen...   \n",
      "3         0   ge he frurn bu he ren he wn he    h w  becue ...   \n",
      "4         0    fr fr n exper n pp n  wul en  gree h  h  l f...   \n",
      "...     ...                                                ...   \n",
      "949995    0   genunel cn unern hw nne cn uppr h  h pn  k u ...   \n",
      "949996    0    rener h ubre  fr cvl cunhpwwwrecrplcwkrulenr...   \n",
      "949997    0                                k n expln wh r nhng   \n",
      "949998    0                                               elee   \n",
      "949999    0   cph re knwn fr celebrng her pve feelng re u f...   \n",
      "\n",
      "                                                   tokens  \n",
      "0       [well, gre, h, he, ehng, bu, he, belef, whle, ...  \n",
      "1                                  [u, re, rgh, r, preen]  \n",
      "2       [u, hve, gven, n, npu, pr, fr, ng, wrng, u, hv...  \n",
      "3       [ge, he, frurn, bu, he, ren, he, wn, he, h, w,...  \n",
      "4       [fr, fr, n, exper, n, pp, n, wul, en, gree, h,...  \n",
      "...                                                   ...  \n",
      "949995  [genunel, cn, unern, hw, nne, cn, uppr, h, h, ...  \n",
      "949996  [rener, h, ubre, fr, cvl, cunhpwwwrecrplcwkrul...  \n",
      "949997                         [k, n, expln, wh, r, nhng]  \n",
      "949998                                             [elee]  \n",
      "949999  [cph, re, knwn, fr, celebrng, her, pve, feelng...  \n",
      "\n",
      "[950000 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-43a1a1ae1787>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-43a1a1ae1787>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\stem\\porter.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m         \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNLTK_EXTENSIONS\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "ps = PorterStemmer()\n",
    "[ps.stem(word) for word in df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
