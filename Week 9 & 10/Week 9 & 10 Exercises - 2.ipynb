{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, json, re, pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sports</td>\n",
       "      <td>Barely better than Gabbert? He was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sports</td>\n",
       "      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sports</td>\n",
       "      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sports</td>\n",
       "      <td>No!! NOO!!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_df = pd.read_json(r'C:\\Users\\Gabe\\Documents\\Bellevue University\\Data Mining\\Week 9 & 10\\categorized-comments.jsonl', lines=True)\n",
    "con_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove punctuations and special characters, makes lower case\n",
    "    Args: text \n",
    "    Output: text\n",
    "    \"\"\"\n",
    "    \n",
    "    text=text.lower()\n",
    "    text=re.sub('</?.*?>',' <>', text)\n",
    "    text=re.sub('\\\\d|\\\\W+|_',' ',text)\n",
    "    text=re.sub('[^a-zA-Z]',\" \", text)\n",
    "    \n",
    "    return text\n",
    "# Create stop words list\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>typical r android dismissing content just beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>you might need a new phone then lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>i have no problems reaching that position on m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>well i mean sure i can believe that on the    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>science_and_technology</td>\n",
       "      <td>gt weren t there reports of gmail adding snoo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      cat                                                txt\n",
       "0  science_and_technology  typical r android dismissing content just beca...\n",
       "1  science_and_technology               you might need a new phone then lol \n",
       "2  science_and_technology  i have no problems reaching that position on m...\n",
       "3  science_and_technology  well i mean sure i can believe that on the    ...\n",
       "4  science_and_technology   gt weren t there reports of gmail adding snoo..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 30000    # sample size\n",
    "replace = True  # with replacement\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "\n",
    "comments = con_df.groupby('cat', as_index=False).apply(fn)\n",
    "\n",
    "# free up memory\n",
    "\n",
    "del con_df\n",
    "\n",
    "comments['txt'] = comments['txt'].apply(lambda x:clean_text(x))\n",
    "comments.reset_index(drop=True, inplace=True)\n",
    "\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "N_FEATURES = 5000\n",
    "N_CLASSES = 4\n",
    "\n",
    "def build_network():\n",
    "    nn = Sequential()\n",
    "    nn.add(Dense(500, activation='relu', input_shape=(N_FEATURES,)))\n",
    "    nn.add(Dense(150, activation='relu'))\n",
    "    nn.add(Dense(N_CLASSES, activation='softmax'))\n",
    "    nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentences = comments['txt'].values\n",
    "y = comments['cat'].values\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size = 0.25, random_state=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "vectorizer.transform(sentences).toarray()\n",
    "\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabe\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Gabe\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7780888888888889\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                392950    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 392,961\n",
      "Trainable params: 392,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "  (0, 993)\t1\n",
      "  (0, 3414)\t1\n",
      "  (0, 4711)\t1\n",
      "  (0, 12122)\t1\n",
      "  (0, 16451)\t1\n",
      "  (0, 28161)\t1\n",
      "  (0, 30040)\t1\n",
      "  (0, 30181)\t1\n",
      "  (0, 34407)\t1\n",
      "  (1, 6222)\t1\n",
      "  (1, 11624)\t1\n",
      "  (1, 15446)\t1\n",
      "  (1, 20683)\t1\n",
      "  (1, 23451)\t1\n",
      "  (1, 27083)\t1\n",
      "  (1, 28120)\t1\n",
      "  (1, 30382)\t1\n",
      "  (1, 31739)\t1\n",
      "  (1, 38422)\t1\n",
      "  (1, 38984)\t1\n",
      "  (2, 1501)\t1\n",
      "  (2, 6154)\t2\n",
      "  (2, 8598)\t1\n",
      "  (2, 14057)\t1\n",
      "  (2, 15863)\t1\n",
      "  :\t:\n",
      "  (67499, 22880)\t1\n",
      "  (67499, 24137)\t1\n",
      "  (67499, 24919)\t1\n",
      "  (67499, 25210)\t1\n",
      "  (67499, 25220)\t1\n",
      "  (67499, 25505)\t1\n",
      "  (67499, 25510)\t1\n",
      "  (67499, 25776)\t1\n",
      "  (67499, 29001)\t1\n",
      "  (67499, 30711)\t1\n",
      "  (67499, 30719)\t1\n",
      "  (67499, 31142)\t1\n",
      "  (67499, 31248)\t1\n",
      "  (67499, 31893)\t1\n",
      "  (67499, 32092)\t1\n",
      "  (67499, 34228)\t1\n",
      "  (67499, 34238)\t3\n",
      "  (67499, 34592)\t1\n",
      "  (67499, 34739)\t5\n",
      "  (67499, 36543)\t1\n",
      "  (67499, 36606)\t1\n",
      "  (67499, 37979)\t1\n",
      "  (67499, 38249)\t1\n",
      "  (67499, 38970)\t1\n",
      "  (67499, 38984)\t2\n",
      "['science_and_technology' 'video_games' 'science_and_technology' ...\n",
      " 'science_and_technology' 'video_games' 'video_games']\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#print(classification_report(y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(confusion_matrix(y_train, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
